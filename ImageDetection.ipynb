{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mubarak-ml/Mubarak-ml/blob/main/ImageDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoAQCGUIuPFr",
        "outputId": "6e9d69c8-59d6-44d2-b1c5-d59cfd09b99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite_model_maker\n",
            "  Downloading tflite_model_maker-0.4.2-py3-none-any.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 14.8 MB/s \n",
            "\u001b[?25hCollecting tflite-support>=0.4.2\n",
            "  Downloading tflite_support-0.4.3-cp38-cp38-manylinux2014_x86_64.whl (60.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.5.0,>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (3.2.2)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (0.29.32)\n",
            "Collecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (6.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (4.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (1.24.3)\n",
            "Collecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 75.6 MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[K     |████████████████████████████████| 840 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (0.8.1)\n",
            "Requirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (2.9.2)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (7.1.2)\n",
            "Collecting scann==1.2.6\n",
            "  Downloading scann-1.2.6-cp38-cp38-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (1.15.0)\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (0.12.0)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (1.3.0)\n",
            "Collecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from tflite_model_maker) (1.21.6)\n",
            "Collecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 67.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (0.11.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (1.2.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite_model_maker) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.53->tflite_model_maker) (57.4.0)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp38-cp38-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 72.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow>=2.6.0\n",
            "  Downloading tensorflow-2.8.4-cp38-cp38-manylinux2010_x86_64.whl (498.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 498.0 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (1.3.5)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (5.4.8)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (3.3.6)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 75.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (1.12.11)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (4.6.0.66)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite_model_maker) (0.5.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.3.1->tflite_model_maker) (2.1.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (2.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (2.8.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (1.57.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (2.23.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (3.19.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (2.8.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (1.22.1)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (2.16.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (2.4.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (2.3.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (1.51.1)\n",
            "Requirement already satisfied: pyarrow<11.0dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (9.0.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (1.48.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite_model_maker) (1.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite_model_maker) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite_model_maker) (7.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite_model_maker) (2022.12.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite_model_maker) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite_model_maker) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite_model_maker) (0.11.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from neural-structured-learning>=1.3.1->tflite_model_maker) (22.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official==2.3.0->tflite_model_maker) (2022.6)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.1->tflite_model_maker) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite_model_maker) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite_model_maker) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa==0.8.1->tflite_model_maker) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1->tflite_model_maker) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 57.9 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (0.28.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (14.0.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite_model_maker) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite_model_maker) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (3.11.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite_model_maker) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons>=0.11.2->tflite_model_maker) (2.7.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (1.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (0.3.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (5.10.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (0.10.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.5->tflite_model_maker) (0.1.7)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.10.2-py3-none-any.whl (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 80.9 MB/s \n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite_model_maker) (1.3)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=98df749b453857de6fc02ec0241c18fd9a332464227550940b357a5ce2300e25\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "Successfully built fire\n",
            "Installing collected packages: llvmlite, tensorflow-estimator, tensorboard, packaging, numba, keras, flatbuffers, tf-slim, tensorflow-model-optimization, tensorflow-addons, tensorflow, sounddevice, sentencepiece, pybind11, py-cpuinfo, dataclasses, tflite-support, tf-models-official, tensorflowjs, scann, neural-structured-learning, fire, tflite-model-maker\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 fire-0.5.0 flatbuffers-22.12.6 keras-2.8.0 llvmlite-0.36.0 neural-structured-learning-1.4.0 numba-0.53.0 packaging-20.9 py-cpuinfo-9.0.0 pybind11-2.10.2 scann-1.2.6 sentencepiece-0.1.97 sounddevice-0.4.5 tensorboard-2.8.0 tensorflow-2.8.4 tensorflow-addons-0.19.0 tensorflow-estimator-2.8.0 tensorflow-model-optimization-0.7.3 tensorflowjs-3.18.0 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.2 tflite-support-0.4.3\n"
          ]
        }
      ],
      "source": [
        "pip install tflite_model_maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYs6y70ip0wT",
        "outputId": "9f84bcec-2444-4751-afcd-e2a59cc7a342"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn90H7JIxJ0w"
      },
      "outputs": [],
      "source": [
        "spec=model_spec.get('efficientdet_lite0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VD_jpZn7yU7B"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data=object_detector.DataLoader.from_csv('gs://cloud-ml-data/img/openimage/csv/salads_ml_use.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H749eNcp1UWp",
        "outputId": "80665180-26c9-4403-d3af-ea309aaaab9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 67s 1s/step - det_loss: 1.7635 - cls_loss: 1.1329 - box_loss: 0.0126 - reg_l2_loss: 0.0635 - loss: 1.8270 - learning_rate: 0.0090 - gradient_norm: 0.8427 - val_det_loss: 1.6576 - val_cls_loss: 1.0993 - val_box_loss: 0.0112 - val_reg_l2_loss: 0.0635 - val_loss: 1.7211\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 25s 1s/step - det_loss: 1.5918 - cls_loss: 1.0611 - box_loss: 0.0106 - reg_l2_loss: 0.0635 - loss: 1.6553 - learning_rate: 0.0100 - gradient_norm: 1.0885 - val_det_loss: 1.5322 - val_cls_loss: 1.0218 - val_box_loss: 0.0102 - val_reg_l2_loss: 0.0635 - val_loss: 1.5957\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 30s 2s/step - det_loss: 1.4162 - cls_loss: 0.9413 - box_loss: 0.0095 - reg_l2_loss: 0.0635 - loss: 1.4797 - learning_rate: 0.0099 - gradient_norm: 1.7421 - val_det_loss: 1.5363 - val_cls_loss: 1.0620 - val_box_loss: 0.0095 - val_reg_l2_loss: 0.0635 - val_loss: 1.5998\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 27s 1s/step - det_loss: 1.2653 - cls_loss: 0.8009 - box_loss: 0.0093 - reg_l2_loss: 0.0635 - loss: 1.3288 - learning_rate: 0.0099 - gradient_norm: 2.1519 - val_det_loss: 1.3488 - val_cls_loss: 0.9023 - val_box_loss: 0.0089 - val_reg_l2_loss: 0.0636 - val_loss: 1.4123\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 43s 2s/step - det_loss: 1.1444 - cls_loss: 0.7184 - box_loss: 0.0085 - reg_l2_loss: 0.0636 - loss: 1.2079 - learning_rate: 0.0098 - gradient_norm: 1.8646 - val_det_loss: 1.1767 - val_cls_loss: 0.7584 - val_box_loss: 0.0084 - val_reg_l2_loss: 0.0636 - val_loss: 1.2403\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 25s 1s/step - det_loss: 1.0782 - cls_loss: 0.6938 - box_loss: 0.0077 - reg_l2_loss: 0.0636 - loss: 1.1417 - learning_rate: 0.0097 - gradient_norm: 1.9256 - val_det_loss: 1.1453 - val_cls_loss: 0.7457 - val_box_loss: 0.0080 - val_reg_l2_loss: 0.0636 - val_loss: 1.2089\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 27s 1s/step - det_loss: 0.9982 - cls_loss: 0.6354 - box_loss: 0.0073 - reg_l2_loss: 0.0636 - loss: 1.0618 - learning_rate: 0.0096 - gradient_norm: 1.8380 - val_det_loss: 1.0632 - val_cls_loss: 0.6675 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0636 - val_loss: 1.1268\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 29s 1s/step - det_loss: 0.9761 - cls_loss: 0.6355 - box_loss: 0.0068 - reg_l2_loss: 0.0636 - loss: 1.0397 - learning_rate: 0.0094 - gradient_norm: 1.7947 - val_det_loss: 1.0186 - val_cls_loss: 0.6219 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0636 - val_loss: 1.0822\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 30s 1s/step - det_loss: 0.9372 - cls_loss: 0.6059 - box_loss: 0.0066 - reg_l2_loss: 0.0636 - loss: 1.0008 - learning_rate: 0.0093 - gradient_norm: 1.9989 - val_det_loss: 1.0012 - val_cls_loss: 0.6069 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0636 - val_loss: 1.0648\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 36s 2s/step - det_loss: 0.8854 - cls_loss: 0.5765 - box_loss: 0.0062 - reg_l2_loss: 0.0636 - loss: 0.9490 - learning_rate: 0.0091 - gradient_norm: 1.9016 - val_det_loss: 1.0381 - val_cls_loss: 0.6407 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0636 - val_loss: 1.1017\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 26s 1s/step - det_loss: 0.8736 - cls_loss: 0.5722 - box_loss: 0.0060 - reg_l2_loss: 0.0636 - loss: 0.9372 - learning_rate: 0.0089 - gradient_norm: 1.9467 - val_det_loss: 0.9522 - val_cls_loss: 0.5833 - val_box_loss: 0.0074 - val_reg_l2_loss: 0.0636 - val_loss: 1.0159\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 30s 1s/step - det_loss: 0.8743 - cls_loss: 0.5690 - box_loss: 0.0061 - reg_l2_loss: 0.0636 - loss: 0.9379 - learning_rate: 0.0087 - gradient_norm: 2.0707 - val_det_loss: 0.9808 - val_cls_loss: 0.6310 - val_box_loss: 0.0070 - val_reg_l2_loss: 0.0636 - val_loss: 1.0444\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 30s 1s/step - det_loss: 0.8664 - cls_loss: 0.5604 - box_loss: 0.0061 - reg_l2_loss: 0.0636 - loss: 0.9301 - learning_rate: 0.0085 - gradient_norm: 2.1872 - val_det_loss: 0.9522 - val_cls_loss: 0.5979 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.0636 - val_loss: 1.0159\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 30s 1s/step - det_loss: 0.8496 - cls_loss: 0.5546 - box_loss: 0.0059 - reg_l2_loss: 0.0636 - loss: 0.9132 - learning_rate: 0.0082 - gradient_norm: 2.1628 - val_det_loss: 0.9471 - val_cls_loss: 0.5931 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.0637 - val_loss: 1.0108\n",
            "Epoch 15/50\n",
            "13/21 [=================>............] - ETA: 7s - det_loss: 0.8182 - cls_loss: 0.5333 - box_loss: 0.0057 - reg_l2_loss: 0.0637 - loss: 0.8818 - learning_rate: 0.0080 - gradient_norm: 2.1433"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-02acc1c2d513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_whole_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retraining the models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[1;32m    121\u001b[0m       validation_ds, validation_steps, val_json_file = self._get_dataset_and_steps(\n\u001b[1;32m    122\u001b[0m           validation_data, batch_size, is_training=False)\n\u001b[0;32m--> 123\u001b[0;31m       return self.model_spec.train(self.model, train_ds, steps_per_epoch,\n\u001b[0m\u001b[1;32m    124\u001b[0m                                    \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                    batch_size, val_json_file)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_dataset, steps_per_epoch, val_dataset, validation_steps, epochs, batch_size, val_json_file)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_experimental\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model=object_detector.create(train_data, model_spec=spec, batch_size=8, train_whole_model=True, validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0W6I6n68nbl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eenVF9w_3FBp",
        "outputId": "570c6126-59b9-4525-aae0-b6effb763d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 9s 9s/step\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'AP': 0.18941297,\n",
              " 'AP50': 0.3357194,\n",
              " 'AP75': 0.18644616,\n",
              " 'APs': -1.0,\n",
              " 'APm': 0.38380203,\n",
              " 'APl': 0.1899867,\n",
              " 'ARmax1': 0.15807597,\n",
              " 'ARmax10': 0.3015285,\n",
              " 'ARmax100': 0.35979834,\n",
              " 'ARs': -1.0,\n",
              " 'ARm': 0.7,\n",
              " 'ARl': 0.35656616,\n",
              " 'AP_/Baked Goods': 0.0658395,\n",
              " 'AP_/Salad': 0.50545835,\n",
              " 'AP_/Cheese': 0.14240992,\n",
              " 'AP_/Seafood': 0.0046913526,\n",
              " 'AP_/Tomato': 0.22866565}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcKMW84-3rKa"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLw3RYDo4WFY",
        "outputId": "06268994-34cd-4a99-ea41-675b410cea7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 69s 3s/step\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'AP': 0.17717487,\n",
              " 'AP50': 0.29842296,\n",
              " 'AP75': 0.1873569,\n",
              " 'APs': -1.0,\n",
              " 'APm': 0.39938316,\n",
              " 'APl': 0.1765684,\n",
              " 'ARmax1': 0.13201426,\n",
              " 'ARmax10': 0.25040108,\n",
              " 'ARmax100': 0.26643047,\n",
              " 'ARs': -1.0,\n",
              " 'ARm': 0.51666665,\n",
              " 'ARl': 0.2638197,\n",
              " 'AP_/Baked Goods': 0.06237624,\n",
              " 'AP_/Salad': 0.4929454,\n",
              " 'AP_/Cheese': 0.10672795,\n",
              " 'AP_/Seafood': 0.0,\n",
              " 'AP_/Tomato': 0.22382474}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate_tflite('model.tflite', test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmG7lK_h6VXS"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "model_path='model.tflite'\n",
        "\n",
        "classes=['???']*model.model_spec.config.num_classes\n",
        "label_map=model.model_spec.config.label_map\n",
        "for label_id, label_name in label_map.as_dict().items():\n",
        "  classes[label_id-1]=label_name\n",
        "\n",
        "COLORS=np.random.randint(0,255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocessing(image_path, input_size):\n",
        "  img=tf.ioread_file(image_path)\n",
        "  img=tf.io.decode_image(img, channels=3)\n",
        "  img=tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image=img\n",
        "  resized_img=tf.image.resize(img, input_size)\n",
        "  resized_img=resized_img[tf.newaxis, :]\n",
        "  resized_img=tf.cast(resized_img, dtype=tf.uint8)\n",
        "  return resized_img, original_image\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  signature_fn=interpreter.get_signature_runner()\n",
        "\n",
        "  output=signature_fn(images=image)\n",
        "  count=int(np.squeeze(output['output_0']))\n",
        "  scores=np.squeeze(output['output_1'])\n",
        "  classes=np.squeeze(output['output_2'])\n",
        "  boxes=np.squeeze(output['output_3'])\n",
        "\n",
        "  results=[]\n",
        "  for i in range(count):\n",
        "    if scores[i]>=threshold:\n",
        "      result={\n",
        "          'bounding_box':boxes[i],\n",
        "          'class_id':classes[i],\n",
        "          'score':scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  _, input_height, input_width,_=interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  preprocessed_image, original_image=preprocessed_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "  )\n",
        "\n",
        "  results=detect_objects(interpreter, preprocessed_image, threshold)\n",
        "\n",
        "  original_image_np=original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    ymin,xmin,ymax, xmax=obj['bounding_box']\n",
        "    xmin=int(xmin*original_image_np.shape[1])\n",
        "    xmax=int(xmax*original_image_np.shape[1])\n",
        "    ymin=int(ymin*original_image_np.shape[0])\n",
        "    ymax=int(ymax*original_image_np.shape[0])\n",
        "\n",
        "    class_id=int(obj['class_id'])\n",
        "\n",
        "    color=[int(c) for c in COLORS[class_id]]\n",
        "    cv2.reactangle(original_image_np, (xmin,ymin), (xmax,ymax), color, 2)\n",
        "\n",
        "    y=ymin-15 if ymin-15>15 else ymin+15\n",
        "    label=\"{}:{:.0f}%\".format(classes[class_id], obj['score']*100)\n",
        "    cv2.putText(original_image_np, label, (xmin,y),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "  original_uint8=original_image_np.astype(np.uint8)\n",
        "  return original_uint8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_8YgN6pJkHzh",
        "outputId": "767d7076-e6bd-4b78-977c-2c59d5ebb8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/img/image.png: No such file or directory\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c9291ad1191c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTEMP_FILE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/img/image.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget -q -O $TEMP_FILE $INPUT_IMAGE_URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMP_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthumbnail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMP_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/img/image.png'"
          ]
        }
      ],
      "source": [
        "INPUT_IMAGE_URL=\"https://storage.googleapis.com/cloud-ml-data/img/opemimage/3/2520/3916261642_0a504acd60_o.jpg\"\n",
        "DETECTION_THRESHOLD=0.3\n",
        "\n",
        "TEMP_FILE='/img/image.png'\n",
        "!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
        "im=Image.open(TEMP_FILE)\n",
        "im.thumbnail((512,512), Image.ANTIALIAS)\n",
        "im.save(TEMP_FILE, 'PNG')\n",
        "\n",
        "interpreter=tf.lite.interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "detection_results_image=run_odt_and_draw_results(\n",
        "    TEMP_FILE,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "Image.fromarray(detection_results_image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1hUpDmsXdGFAfZh99z_herp0DenoGui8x",
      "authorship_tag": "ABX9TyNpvcRYVLuZK7w1buIrQ/3j",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}